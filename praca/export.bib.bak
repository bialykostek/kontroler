@report{Engel2007,
   author = {Walter Hans Engel and Eth Zurich and A Noth and R Siegwart and W Engel and André Noth and Roland Siegwart},
   title = {Design of Solar Powered Airplanes for Continuous Flight Design of Solar Powered Airplanes for Continuous Flight Design of Solar Powered Airplanes for Continuous Flight},
   url = {http://www.sky-sailor.ethz.ch/docs/Thesis_Noth_2008.pdf},
   year = {2007},
}
@article{Wu2022,
   abstract = {Complex 3D obstacle environments raise high requirements of the rapid reaction capability and safety aiming at the maneuver control for obstacle avoidance (MCOA) of fixed-wing unmanned aerial vehicles (FUAVs). Considering the above demands, a learning-based reactive MCOA framework is proposed in this paper. First, the fundamental controller in this framework composed of the interfered fluid dynamical system (IFDS) guidance law and back-stepping control loops is established. Then, aiming at the rapid reaction requirement, a deep-reinforcement-learning-based (DRL-based) reactive online decision-making mechanism for obstacle avoidance matched with the IFDS guidance law is proposed. And aiming at the high safety requirement, the closed-loop system composed of the above fundamental controller and the FUAV 6-DOF nonlinear dynamic model is introduced into the DRL training environments so that the FUAV state transitions considering the characteristics of controllers and dynamics can be realized, and the corresponding reward functions can be calculated accordingly. On this basis, the optimal guidance instructions with high trackability can be resolved in real time using the actor networks trained by the proposed DRL-based mechanism, and the safe maneuver control in complex obstacle environments can be achieved. Finally, a normative modeling method of DRL training environments matched with the reactive MCOA framework is proposed to promote training efficiency. The effectiveness of the proposed framework is demonstrated by simulations.},
   author = {Jianfa Wu and Honglun Wang and Yiheng Liu and Menghua Zhang and Tiancai Wu},
   doi = {10.1016/j.ast.2022.107623},
   issn = {12709638},
   journal = {Aerospace Science and Technology},
   keywords = {Deep reinforcement learning,Fixed-wing unmanned aerial vehicle,Interfered fluid dynamical system,Obstacle avoidance,Reactive maneuver control,Training environment},
   month = {7},
   publisher = {Elsevier Masson s.r.l.},
   title = {Learning-based fixed-wing UAV reactive maneuver control for obstacle avoidance},
   volume = {126},
   year = {2022},
}
@report{Rapinett2009,
   author = {Annabel Rapinett},
   title = {Zephyr: A High Altitude Long Endurance Unmanned Air Vehicle},
   year = {2009},
}
@book{,
   author = {Institute of Electrical and Electronics Engineers.},
   isbn = {9781467356435},
   pages = {5863},
   title = {Robotics and Automation (ICRA), 2013 IEEE International Conference on : date 6-10 May 2013.},
}
@article{,
   title = {Developing a solar rechargeable aircraft},
}
@book{,
   abstract = {"IEEE Catalog Number: CFP1729V-ART."},
   author = {Institute of Electrical and Electronics Engineers and Nat︠s︡ionalʹnyĭ aviat︠s︡iĭnyĭ universytet (Ukraine) and Institute of Electrical and Electronics Engineers. Ukraine Section. Central Ukraine SP/AES Societies Joint Chapter},
   isbn = {9781538618172},
   title = {2017 IEEE 4th International Conference Actual Problems of Unmanned Aerial Vehicles Developments (APUAVD) : proceedings : October 17-19, 2017, Kyiv, Ukraine},
}
@article{Chen2021,
   abstract = {Aiming at the attitude control problem of fixed wing UAV, this paper introduces S-plane control, which has good control effect in the field of underwater UAV, into the attitude control of UAV. At the same time, aiming at the problem that the coefficient setting of parameters in S-plane control completely depends on experience and cannot be adjusted adaptively, the radial basis function neural network (RBFNN) is introduced, and a neural network S-plane control model which can realize on-line adaptive adjustment of the coefficient of parameters in S-plane control is proposed. The simulation results based on the data of a certain UAV show that compared with the S-plane control, the proposed neural network S-plane control model has the characteristics of fast response speed, strong anti-interference ability, and strong robustness. In addition, it also has the function of adaptive adjustment, which shows good control performance.},
   author = {Pengyun Chen and Guobing Zhang and Tong Guan and Meini Yuan and Jian Shen},
   doi = {10.1109/ACCESS.2021.3093768},
   issn = {21693536},
   journal = {IEEE Access},
   keywords = {Fixed wing UAV,S-plane control,adaptive adjustment,radial basis function neural network (RBFNN)},
   pages = {93927-93936},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {The Motion Controller Based on Neural Network S-Plane Model for Fixed-Wing UAVs},
   volume = {9},
   year = {2021},
}
@inproceedings{Chowdhury2022,
   abstract = {Applications of deep reinforcement learning (RL) based control have mainly focused on multi-rotor unmanned aerial systems (UASs). The limited number of research on AI-based flight controllers for fixed-wing UASs platforms lacks rigorous validation and verification (V&V) flight tests. Simulation V&V are conducted for AI-based controllers and only AI-based guidance has been implemented for the flight test verification. The complexity and scarcity of research on AI-based flight controllers for fixed-wing UASs are multilayers, however high speed and inertia of this class of aircraft, structural load limitations, stall speed and angle of attack, and large impact of aerodynamic forces and moments are among the main reasons. Tight tracking requirements and nonlinear and unsteady aerodynamics in presence of external disturbances only exacerbate the complexity. The traditional controller design methods (e.g., Modern and Classical Control) heavily rely on the quality of aircraft physics-based dynamic models. Robust controllers address the uncertainties in the dynamic model by trading off the performance of flight controllers. This work presents the development of a policy-based flight controller (longitudinal-directional) for a fixed-wing UAS using a model-free deep RL algorithm called PPO (Proximal Policy Optimization). The UAS has a 2.66 m wingspan, weighs 6.4 Kg, and cruises at 15.3 m/s. The controller is trained in simulation using a low-fidelity dynamic model with appropriate dynamic randomization to tackle the issue of parametric uncertainties. To further improve the transferability of the controller, we also incorporate memory functions into the policy using RNN (recurrent neural network) architecture. We opt for the PPO Deep RL algorithm for its monotonic and stable policy improvement characteristics and less sensitivity to hyper-parameters. The developed controller performance is first validated in HiTL (hardware-in-the-loop) simulations. Several actual flight tests are conducted for the verification of the developed controller. The AI-based controller is flight tested in different weather conditions to quantify its robustness toward external disturbances. Both simulation and flight test results are presented in this work.},
   author = {Mozammal Chowdhury and Shawn Keshmiri},
   doi = {10.1109/AERO53065.2022.9843777},
   isbn = {9781665437608},
   issn = {1095323X},
   journal = {IEEE Aerospace Conference Proceedings},
   publisher = {IEEE Computer Society},
   title = {Design and Flight Test Validation of an AI-Based Longitudinal Flight Controller for Fixed-wing UASs},
   volume = {2022-March},
   year = {2022},
}
@web_page{,
   title = {en.wikipedia.org/wiki/Artificial_neural_network},
}
@web_page{,
   title = {https://pl.wikipedia.org/wiki/Winglet},
}
@web_page{,
   title = {en.wikipedia.org/wiki/Multilayer_perceptron},
}
@web_page{,
   title = {https://docs.px4.io/main/en/config_mc/pid_tuning_guide_multicopter.html},
}
@web_page{,
   title = {https://docs.px4.io/main/en/flight_stack/controller_diagrams.html},
}
